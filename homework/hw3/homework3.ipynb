{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483338cf-84a3-403c-b1f4-36d9d4ae9d68",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "\n",
    "## William Olsen\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "We're going to briefly look at truth tables. As an example let's assume we have a 100 photos, some of birds and some of people. In a truth table you assume you can categorize the true answerâ€”let's say you pay an undergraduate to sort the photos into birds and people. Then you want to have an automated sorting algorithm. However that works, whether it is by looking a the color at the center of photo or using a neural network (NN), it will also sort the photos but imperfectly. Given two sorts you can then arrange a truth table:\n",
    "\n",
    "|              | True Bird | True Person |\n",
    "|--------------|-----------|------------|\n",
    "| NN Bird | 45      | 5        |\n",
    "| NN Person      | 3  | 47       |\n",
    "\n",
    "There are 48 birds and 52 People (columns), and there are 8 miscategorizations. The NN called three of the birds people, and 5 of the people birds.\n",
    "\n",
    "This is useful because it not only shows the number of errors, but the type, and not all errors are created equal. Let's say our identification system is being used to keep birds from escaping the aviary at the zoo by locking the aviary door when a bird is trying to escape. We really don't want to let birds escape, but locking a person in for 30 extra seconds is not a big deal. In this case false bird identification is not so bad, but false person identification lets a bird escape.\n",
    "\n",
    "Let's say the above truth table is the current system, and you've developed a new algorithm (NA) with the following truth table:\n",
    "\n",
    "|              | True Bird | True Person |\n",
    "|--------------|-----------|------------|\n",
    "| NN Bird | 47      | 10        |\n",
    "| NN Person      | 1  | 42       |\n",
    "\n",
    "> Note: For the above truth table there was a typo in the assignment which resulted in there being 11+42 = 53 people rather than 52.  To balance the numberI decreased the number of true people identified as birds to be 10 rather than 11."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5b8487-ab2a-44d8-9052-1d535fed2f2c",
   "metadata": {},
   "source": [
    "#### Part A\n",
    "\n",
    "**Which algorithm makes the fewest mistakes?**\n",
    "\n",
    "In both algorithms we are classifying 100 things - with 48 being a true bird and 52 being a true person.  We see that in the first model, 50 things are classified as Birds and 50 as People.  Provided these classifications we incorrectly classified 5 people as birds and 3 birds as people thus giving us 8 mistakes.\n",
    "\n",
    "In the second algorithm we classified 57 things as birds and 43 things as people.  Provided these claissifications we incorrectly classified 10 people as birds and 1 bird as a person thus giving us 11 mistakes.\n",
    "\n",
    "From this we can calculate that NN's overall accuracy is 92% while NA's overall accuracy is 89%.  Thus algorithm NN makes the fewest mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aca31d-5f6e-412f-ae67-e32301785930",
   "metadata": {},
   "source": [
    "#### Part B\n",
    "\n",
    "**Which algorithm is better for the zoo?**\n",
    "\n",
    "To determine which algorithm is better for the zoo we would like the algorithm that has the highest classification accuracy for animals - in this case birds.  Thus we will calculate the classification accuracy for birds for both algorithms.\n",
    "\n",
    "Algorithm NN classified 3 birds as people so it's classification accuracy for birds is 45 / 48 = 93.75%.\n",
    "\n",
    "Algorithm NA classified 1 bird as a person so it's classification accuracy for birds is 47 / 48 = 97.92%.\n",
    "\n",
    "Thus we would choose the NA algorithm for the zoo because it is better at correctly classifitying birds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233df66a-9bec-4de6-9096-1892d1218917",
   "metadata": {},
   "source": [
    "#### Part C\n",
    "\n",
    "**During the pandemic the number of visitors plummets, and it is only the zoo keeper visiting. So instead of 52% of the photos taken at the aviary door being people, it is now only 1%. Make new truth tables for both algorithms.**\n",
    "\n",
    "In this new situation we will have a base number of 48 bird photos and 1 photo of a person.\n",
    "\n",
    "We know that for algorithm NN we have a 45/48 = 93.75% chance to correctly classify a bird and thus a 6.25% chance to incorrectly classify a bird as a person.  Also we have a 47/52 = 90.38% chance to correctly classify a person and thus a 9.62% chance to incorrectly classify a person as a bird.  Using these percentages we can create a new truth table however because we only have 1 photo of a person we will get a fractional number of people.  Lets boost the number of photos that we have taken by a factor of 100.  We will also round the probability of identifying a person correctly to 90% and thus giving a 10% chance to incorrectly identify a person.  With this we have the following truth table for 100 true photos of a person and 4800 true photos of birds for a total of 4900 photos:\n",
    "\n",
    "|              | True Bird | True Person |\n",
    "|--------------|-----------|------------|\n",
    "| NN Bird | 4500      | 10        |\n",
    "| NN Person      | 300  | 90       |\n",
    "\n",
    "For algorithm NA we have a 47/48 = 97.92% chance to correctly classify a bird and thus a 2.08% percent chance to incorrectly classify a bird as a perosn.  Similarly, we have a 42/52 = 80.77% chance to correctly classify a person and a 19.23% chance to incorrectly classify a person as a bird.  Using these percentages we can create a new truth table for the algorithm, however bedcause we knoly have 1 photo of a person we will get a fractional number of people.  Lets boost the number of photos that we have taken by a factor of 100.  We will also round the probability of identifying a person correctly to 81% and thus giving a chance of 19% to incorrectly identify a person as a bird.  With this we have the following truth table for 100 true photos of a person and 4800 true photos of birds for a total of 4900 photos:\n",
    "\n",
    "|              | True Bird | True Person |\n",
    "|--------------|-----------|------------|\n",
    "| NN Bird | 4700      | 19        |\n",
    "| NN Person      | 100  | 81       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c2897b-4263-4501-9f38-4792f60c6ea0",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "In this section we will do an internet scavenger hunt to find the analytic pdf for some interesting distributions.\n",
    "\n",
    "#### Part A\n",
    "\n",
    "**What is the pdf of the sum of two identical exponential distributions?**\n",
    "\n",
    "The PDF of two identical exponential distributions is the convolution of their PDFs.  First lets list the equation for the PDF of an exponential distribution:\n",
    "\n",
    "$$\\text{pdf}(x) = \\lambda e^{-\\lambda x}$$\n",
    "\n",
    "Now in the situation when we have two identical exponential distributions we know that $\\lambda_1 = \\lambda_2 = \\lambda$  Provided this result we will get the following convolution distribution - which is the distribution of the sum of two identical exponential distributions where random variable $Z = X_1 + X_2$:\n",
    "\n",
    "$$\\text{pdf}_{sum}(z) = \\lambda^2 z e^{-\\lambda z}$$\n",
    "\n",
    "This resulting distribution is equivalent to an Erlang distribution with shape 2 (which is k) and parameter $\\lambda$.  The Erlang distribution has the following equation:\n",
    "\n",
    "$$\\text{pdf}_{erlang}(x, k) = \\frac{\\lambda^k x^{k-1} e^{-\\lambda x}}{(k-1)!}$$\n",
    "\n",
    "Additonally, it is of note that the Erlang distribution is a special case of the gamma distribution when the parameter $k$ is positive and distritized. \n",
    "\n",
    "Finally, if random variable $X\\sim Gamma(1, 1/\\lambda)$ then random variable $X$ is for an exponential distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b52fbb-660b-47ae-9090-8f4417078f07",
   "metadata": {},
   "source": [
    "#### Part B\n",
    "\n",
    "**What is the pdf of the ratio of two zero-mean unity variance normal distributions $X_1/X_2$?**\n",
    "\n",
    "If we define a random vairable $Z=X_1/X_2$ where $X_1,X_2$ are zero-mean unity variance normal distributions with PDFs as follows:\n",
    "\n",
    "$$\\text{pdf}(x) = \\frac{e^{-x^2/2}}{\\sqrt{2\\pi}}$$\n",
    "\n",
    "Then random variable Z will have the following PDF:\n",
    "\n",
    "$$\\text{pdf}(z) = \\frac{1}{\\pi (z^2 + 1)}$$\n",
    "\n",
    "Which is the probability density function of a standard Cauchy distribution.  This $Z$ is a Cauchy random variable.\n",
    "\n",
    "The general Cauchy distribution has a PDF of:\n",
    "\n",
    "$$\\frac{1}{\\pi \\gamma [1 + (\\frac{x - x_0}{\\gamma})^2]}$$\n",
    "\n",
    "Thus we can conclude that the ratio of two zero-mean unity variance normal distribution is a Cauchy distribution with parameter $x_0=0$ and $\\gamma=1$.  A Cauchy distribution is also sometimes called a Lorentz Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aecb36-56cc-498e-93d4-f6ffa3d01ea4",
   "metadata": {},
   "source": [
    "#### Part C\n",
    "\n",
    "**So far we have looked at 1D probability distributions, but it is possible to have a multi-dimensional vector distribution. A simple first introduction is the 2D Guassian; it looks like a smeared spot. Mathematically this is given by $X\\widehat{i} + Y\\widehat{j}$ where both $X$ and $Y$ are drawn from 1D Gaussian distributions. If I measure the amplitude of this vector, what is its pdf? (Hint, the amplitude is always positive.)**\n",
    "\n",
    "Generally the when we have Gaussian distributions vectors the overall distribution is a Multivariate normal distribution.  Here we only have a vector of length 2 and thus our distribution falls into the bivariate case.  In the situation where we are taking the vector amplitude of a vector that has two components that are bivariate normally distributed (centered at zero) we will get a Rayleigh distribution.  \n",
    "\n",
    "The case of the vector amplitude distribution being a Rayleigh distribution is dependent on the two bivariate normally distributed random variables having the same mean and variance.  In the situation where they do not have the same variance the result will yield a Hoyt distribution, sometimes known as a Nakagami distribution.\n",
    "\n",
    "Mathematically when we have a vector with components $X_1$ and $X_2$ that are bivariant normally distributed, their PDFs will be:\n",
    "\n",
    "$$\\frac{1}{\\sqrt{2\\pi \\sigma^2}} e^{-x_i^2 / (2\\sigma^2)}$$\n",
    "\n",
    "Then our the PDF of $Z = \\sqrt{X_1^2 + X_2^2}$ will be:\n",
    "\n",
    "$$\\frac{z}{\\sigma^2} e^{-x^2/(2\\sigma^2)}$$\n",
    "\n",
    "Which is exactly the Rayleigh distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b285c64-2885-4e26-bf6e-2b998fa2b1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
