{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483338cf-84a3-403c-b1f4-36d9d4ae9d68",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "\n",
    "## William Olsen\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "We're going to briefly look at truth tables. As an example let's assume we have a 100 photos, some of birds and some of people. In a truth table you assume you can categorize the true answerâ€”let's say you pay an undergraduate to sort the photos into birds and people. Then you want to have an automated sorting algorithm. However that works, whether it is by looking a the color at the center of photo or using a neural network (NN), it will also sort the photos but imperfectly. Given two sorts you can then arrange a truth table:\n",
    "\n",
    "|              | True Bird | True Person |\n",
    "|--------------|-----------|------------|\n",
    "| NN Bird | 45      | 5        |\n",
    "| NN Person      | 3  | 47       |\n",
    "\n",
    "There are 48 birds and 52 People (columns), and there are 8 miscategorizations. The NN called three of the birds people, and 5 of the people birds.\n",
    "\n",
    "This is useful because it not only shows the number of errors, but the type, and not all errors are created equal. Let's say our identification system is being used to keep birds from escaping the aviary at the zoo by locking the aviary door when a bird is trying to escape. We really don't want to let birds escape, but locking a person in for 30 extra seconds is not a big deal. In this case false bird identification is not so bad, but false person identification lets a bird escape.\n",
    "\n",
    "Let's say the above truth table is the current system, and you've developed a new algorithm (NA) with the following truth table:\n",
    "\n",
    "|              | True Bird | True Person |\n",
    "|--------------|-----------|------------|\n",
    "| NN Bird | 47      | 11        |\n",
    "| NN Person      | 1  | 42       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5b8487-ab2a-44d8-9052-1d535fed2f2c",
   "metadata": {},
   "source": [
    "#### Part A\n",
    "\n",
    "Which algorithm makes the fewest mistakes?\n",
    "\n",
    "In both algorithms we are classifying 100 things - with 48 being a true bird and 52 being a true person.  We see that in the first model, 50 things are classified as Birds and 50 as People.  Provided these classifications we incorrectly classified 5 people as birds and 3 birds as people thus giving us 8 mistakes.\n",
    "\n",
    "In the second algorithm we classified 58 things as birds and 43 things as people.  Provided these claissifications we incorrectly classified 11 people as birds and 1 bird as a person thus giving us 12 mistakes.\n",
    "\n",
    "From this we can calculate that NN's overall accuracy is 92% while NA's overall accuracy is 88%.  Thus algorithm NN makes the fewest mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aca31d-5f6e-412f-ae67-e32301785930",
   "metadata": {},
   "source": [
    "#### Part B\n",
    "\n",
    "Which algorithm is better for the zoo?\n",
    "\n",
    "To determine which algorithm is better for the zoo we would like the algorithm that has the highest classification accuracy for animals - in this case birds.  Thus we will calculate the classification accuracy for birds for both algorithms.\n",
    "\n",
    "Algorithm NN classified 3 birds as people so it's classification accuracy for birds is 45 / 48 = 93.75%.\n",
    "\n",
    "Algorithm NA classified 1 bird as a person so it's classification accuracy for birds is 47 / 48 = 97.92%.\n",
    "\n",
    "Thus we would choose the NA algorithm for the zoo because it is better at correctly classifitying birds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233df66a-9bec-4de6-9096-1892d1218917",
   "metadata": {},
   "source": [
    "#### Part C\n",
    "\n",
    "During the pandemic the number of visitors plummets, and it is only the zoo keeper visiting. So instead of 52% of the photos taken at the aviary door being people, it is now only 1%. Make new truth tables for both algorithms.\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c2897b-4263-4501-9f38-4792f60c6ea0",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "In this section we will do an internet scavenger hunt to find the analytic pdf for some interesting distributions.\n",
    "\n",
    "#### Part A\n",
    "\n",
    "What is the pdf of the sum of two identical exponential distributions?\n",
    "\n",
    "The PDF of two identical exponential distributions is the convolution of their PDFs.  First lets list the equation for the PDF of an exponential distribution:\n",
    "\n",
    "$$\\text{pdf}(x) = \\lambda e^{-\\lambda x}$$\n",
    "\n",
    "Now in the situation when we have two identical exponential distributions we know that $\\lambda_1 = \\lambda_2 = \\lambda$  Provided this result we will get the following convolution distribution - which is the distribution of the sum of two identical exponential distributions where random variable $Z = X_1 + X_2$:\n",
    "\n",
    "$$\\text{pdf}_{sum}(z) = \\lambda^2 z e^{-\\lambda z}$$\n",
    "\n",
    "This resulting distribution is equivalent to an Erlang distribution with shape 2 (which is k) and parameter $\\lambda$.  The Erlang distribution has the following equation:\n",
    "\n",
    "$$\\text{pdf}_{erlang}(x, k) = \\frac{\\lambda^k x^{k-1} e^{-\\lambda x}}{(k-1)!}$$\n",
    "\n",
    "Additonally, it is of note that the Erlang distribution is a special case of the gamma distribution when the parameter $k$ is positive and distritized. \n",
    "\n",
    "Finally, if random variable $X\\sim Gamma(1, 1/\\lambda)$ then random variable $X$ is for an exponential distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b52fbb-660b-47ae-9090-8f4417078f07",
   "metadata": {},
   "source": [
    "#### Part B\n",
    "\n",
    "What is the pdf of the ratio of two zero-mean unity variance normal distributions $X_1/X_2$?\n",
    "\n",
    "If we define a random vairable $Z=X_1/X_2$ where $X_1,X_2$ are zero-mean unity variance normal distributions with PDFs as follows:\n",
    "\n",
    "$$\\text{pdf}(x) = \\frac{e^{-x^2/2}}{\\sqrt{2\\pi}}$$\n",
    "\n",
    "Then random variable Z will have the following PDF:\n",
    "\n",
    "$$\\text{pdf}(z) = \\frac{1}{\\pi (z^2 + 1)}$$\n",
    "\n",
    "Which is the probability density function of a standard Cauchy distribution.  This $Z$ is a Cauchy random variable.\n",
    "\n",
    "The general Cauchy distribution has a PDF of:\n",
    "\n",
    "$$\\frac{1}{\\pi \\gamma [1 + (\\frac{x - x_0}{\\gamma})^2]}$$\n",
    "\n",
    "Thus we can conclude that the ratio of two zero-mean unity variance normal distribution is a Cauchy distribution with parameter $x_0=0$ and $\\gamma=1$.  A Cauchy distribution is also sometimes called a Lorentz Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aecb36-56cc-498e-93d4-f6ffa3d01ea4",
   "metadata": {},
   "source": [
    "#### Part C\n",
    "\n",
    "So far we have looked at 1D probability distributions, but it is possible to have a multi-dimensional vector distribution. A simple first introduction is the 2D Guassian; it looks like a smeared spot. Mathematically this is given by $X\\widehat{i} + Y\\widehat{j}$ where both $X$ and $Y$ are drawn from 1D Gaussian distributions. If I measure the amplitude of this vector, what is its pdf? (Hint, the amplitude is always positive.)\n",
    "\n",
    "Generally the when we have Gaussian distributions vectors the overall distribution is a Multivariate normal distribution.  Here we only have a vector of length 2 thus our components are bivariate normally distributed. \n",
    "\n",
    "\n",
    "Relevant links for writing answer:\n",
    "https://en.wikipedia.org/wiki/Rayleigh_distribution, Relation to random vector length section.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Noncentral_chi_distribution, sum of normal's with differant variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7d0b8-b238-437c-b86d-df8ad085449f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01831ab0-9802-4caa-a741-333b7ec0c6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38350ca8-0304-47a9-933e-93091e36be31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e962d-7e7c-4aa7-b47e-ef45a074a8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b285c64-2885-4e26-bf6e-2b998fa2b1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1581bf-9c6d-4349-abd8-e6af5a640ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ask about typo for NA - sum is 101?\n",
    "\n",
    "# TODO: ask about how to classify the person - do we just say that the accuracy is\n",
    "# large enough that we assume we will correctly classify them?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
